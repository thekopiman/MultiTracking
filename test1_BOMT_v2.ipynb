{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import datetime\n",
    "import re\n",
    "import shutil\n",
    "from collections import deque\n",
    "import argparse\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.optim import AdamW\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.gridspec import GridSpec\n",
    "\n",
    "from simulation.simulations.data_generator import DataGenerator\n",
    "from TransformerMOT.util.misc import save_checkpoint, update_logs\n",
    "from TransformerMOT.util.load_config_files import load_yaml_into_dotdict\n",
    "from TransformerMOT.util.plotting import output_truth_plot, compute_avg_certainty, get_constrastive_ax, get_false_ax, \\\n",
    "    get_total_loss_ax, get_state_uncertainties_ax\n",
    "from TransformerMOT.util.logger import Logger\n",
    "from TransformerMOT.models.BOMTv2 import BOMT\n",
    "from simulation.simulations.data_generator import DataGenerator, get_single_training_example\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using seed: 571020960\n"
     ]
    }
   ],
   "source": [
    "task_params = r\"C:\\Users\\chiny\\OneDrive - Nanyang Technological University\\Y3S2 (Internship)\\MultiTracking\\configs\\tasks\\task2.yaml\"\n",
    "model_params = r\"C:\\Users\\chiny\\OneDrive - Nanyang Technological University\\Y3S2 (Internship)\\MultiTracking\\configs\\models\\BOMTv2.yaml\"\n",
    "\n",
    "params = load_yaml_into_dotdict(task_params)\n",
    "params.update(load_yaml_into_dotdict(model_params))\n",
    "\n",
    "if params.general.pytorch_and_numpy_seed is None:\n",
    "    random_data = os.urandom(4)\n",
    "    params.general.pytorch_and_numpy_seed = int.from_bytes(random_data, byteorder=\"big\")\n",
    "print(f'Using seed: {params.general.pytorch_and_numpy_seed}')\n",
    "\n",
    "if params.training.device == 'auto':\n",
    "    params.training.device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from TransformerMOT.util.misc import NestedTensor\n",
    "\n",
    "data_generator = DataGenerator(params=params)\n",
    "training_nested_tensor, labels, unique_measurement_ids, target_coordinates = data_generator.get_batch()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m model1 \u001b[38;5;241m=\u001b[39m \u001b[43mBOMT\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m# checkpoint = torch.load(r\"results\\train2_2phases_1\\checkpoints\\checkpoint_gradient_step_1615.pth\",map_location=\"cuda\")\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# model1.load_state_dict(checkpoint[\"model_state_dict\"])\u001b[39;00m\n\u001b[0;32m      4\u001b[0m res \u001b[38;5;241m=\u001b[39m model1(training_nested_tensor\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n",
      "File \u001b[1;32mc:\\Users\\chiny\\OneDrive - Nanyang Technological University\\Y3S2 (Internship)\\MultiTracking\\TransformerMOT\\models\\BOMTv2.py:72\u001b[0m, in \u001b[0;36mBOMT.__init__\u001b[1;34m(self, params)\u001b[0m\n\u001b[0;32m     59\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmeasurement_normalization_factor \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(\n\u001b[0;32m     60\u001b[0m     [\n\u001b[0;32m     61\u001b[0m         params\u001b[38;5;241m.\u001b[39mdata_generation\u001b[38;5;241m.\u001b[39mdimension[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     67\u001b[0m     ]\n\u001b[0;32m     68\u001b[0m )\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparams\u001b[38;5;241m.\u001b[39mtraining\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[0;32m     69\u001b[0m \u001b[38;5;66;03m# position, velocity, angle, d\u001b[39;00m\n\u001b[0;32m     70\u001b[0m \u001b[38;5;66;03m# Make sure not to normalise d as it will be normalized together with position\u001b[39;00m\n\u001b[1;32m---> 72\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfov_rescaling_factor \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmeasurement_normalization_factor\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m4\u001b[39;49m\n\u001b[0;32m     73\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstarting_dimension \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(params\u001b[38;5;241m.\u001b[39mdata_generation\u001b[38;5;241m.\u001b[39mdimension[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m])\n\u001b[0;32m     75\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfalse_detect_embedding \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     76\u001b[0m     nn\u001b[38;5;241m.\u001b[39mEmbedding(\u001b[38;5;241m1\u001b[39m, params\u001b[38;5;241m.\u001b[39march\u001b[38;5;241m.\u001b[39md_model)\n\u001b[0;32m     77\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m params\u001b[38;5;241m.\u001b[39march\u001b[38;5;241m.\u001b[39mfalse_detect_embedding\n\u001b[0;32m     78\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     79\u001b[0m )\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model1 = BOMT(params).to(\"cuda\")\n",
    "# checkpoint = torch.load(r\"results\\train2_2phases_1\\checkpoints\\checkpoint_gradient_step_1615.pth\",map_location=\"cuda\")\n",
    "# model1.load_state_dict(checkpoint[\"model_state_dict\"])\n",
    "res = model1(training_nested_tensor.to(\"cuda\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = model1.forward(\n",
    "                measurements=training_nested_tensor.to(\"cuda\"),\n",
    "                target_coordinates=target_coordinates.to(\"cuda\"),\n",
    "                unique_id=unique_measurement_ids.to(\"cuda\"),\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 1020])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res[-1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.set_printoptions(threshold=10_000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.,  0.,  0.,  2.,  1.,  0.,  1.,  2.,  0.,  1.,  2.,  0.,  0.,  0.,\n",
       "          1.,  2.,  0.,  1.,  0.,  0.,  1.,  0.,  1.,  0.,  1.,  0.,  2.,  0.,\n",
       "          0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,  2.,  0.,\n",
       "          1.,  0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  1.,  2.,  0.,  1.,\n",
       "          0.,  2.,  0.,  0.,  2.,  1.,  0.,  2.,  1.,  0.,  0.,  0.,  0.,  2.,\n",
       "          1.,  0.,  1.,  1.,  0.,  0.,  2.,  0.,  0.,  2.,  0.,  1.,  1.,  0.,\n",
       "          1.,  0.,  2.,  1.,  0.,  2.,  1.,  0.,  1.,  0.,  2.,  0.,  0.,  1.,\n",
       "          0.,  0.,  1.,  2.,  0.,  0.,  2.,  1.,  0.,  0.,  0.,  0.,  0.,  1.,\n",
       "          0.,  1.,  0.,  1.,  1.,  0.,  0.,  2.,  1.,  1.,  0.,  0.,  0.,  1.,\n",
       "          2.,  0.,  0.,  0.,  1.,  2.,  1.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,\n",
       "          0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  1.,  0.,  0.,  2.,  0.,\n",
       "          0.,  0.,  1.,  0.,  1., -2., -2., -2., -2., -2., -2., -2., -2., -2.,\n",
       "         -2., -2., -2., -2., -2., -2., -2., -2., -2., -2., -2., -2., -2., -2.,\n",
       "         -2., -2., -2., -2., -2., -2., -2., -2., -2., -2., -2., -2., -2., -2.,\n",
       "         -2., -2., -2., -2., -2., -2., -2., -2., -2., -2., -2., -2., -2., -2.,\n",
       "         -2., -2., -2., -2., -2., -2., -2., -2., -2., -2., -2., -2., -2., -2.,\n",
       "         -2., -2., -2., -2., -2., -2., -2., -2., -2., -2., -2., -2., -2., -2.,\n",
       "         -2., -2., -2., -2., -2., -2., -2., -2., -2., -2., -2., -2., -2., -2.,\n",
       "         -2., -2., -2.],\n",
       "        [ 1.,  0.,  1.,  0.,  0.,  0.,  2.,  1.,  1.,  0.,  0.,  0.,  2.,  0.,\n",
       "          1.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,  2.,  2.,  0.,  1.,\n",
       "          0.,  0.,  0.,  1.,  0.,  1.,  2.,  0.,  0.,  0.,  0.,  1.,  2.,  0.,\n",
       "          1.,  0.,  2.,  1.,  1.,  0.,  0.,  1.,  2.,  2.,  0.,  0.,  2.,  0.,\n",
       "          1.,  2.,  1.,  0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,  1.,  0.,  1.,\n",
       "          0.,  0.,  0.,  0.,  0.,  0.,  2.,  0.,  1.,  1.,  0.,  2.,  0.,  2.,\n",
       "          0.,  0.,  1.,  1.,  0.,  1.,  2.,  0.,  0.,  2.,  1.,  0.,  0.,  0.,\n",
       "          1.,  0.,  0.,  0.,  0.,  1.,  0.,  2.,  1.,  2.,  0.,  0.,  0.,  0.,\n",
       "          1.,  2.,  0.,  0.,  1.,  1.,  0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,\n",
       "          0.,  1.,  0.,  0.,  1.,  0.,  1.,  2.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "          0.,  1.,  0.,  1.,  2.,  0.,  0.,  1.,  1.,  0.,  1.,  0.,  0.,  1.,\n",
       "          1.,  0.,  1.,  0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,  1.,  0.,  1.,\n",
       "          2.,  1.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,  2.,  0.,  0.,  2.,  1.,\n",
       "          0.,  0.,  0.,  1.,  0.,  0.,  2.,  2.,  0.,  1.,  1.,  0.,  1.,  0.,\n",
       "          0.,  1.,  2.,  0.,  0.,  1.,  0.,  1.,  2.,  2.,  0.,  1.,  0.,  0.,\n",
       "          0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,  1.,  2.,  0.,  1.,  0.,\n",
       "          1.,  0.,  0.,  1.,  2.,  1.,  0.,  2.,  0.,  0.,  0.,  1.,  2.,  1.,\n",
       "          0.,  2.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,  2.,  1.,  0.,\n",
       "          2.,  1.,  0.]], device='cuda:0')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_measurement_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
      "        -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
      "        -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
      "        -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
      "        -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
      "        -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
      "        -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
      "        -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
      "        -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
      "        -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
      "        -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
      "        -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
      "        -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
      "        -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
      "        -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
      "        -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
      "        -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
      "        -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
      "        -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
      "        -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
      "        -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
      "        -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
      "        -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
      "        -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
      "        -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
      "        -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
      "        -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
      "        -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
      "        -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
      "        -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
      "        -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
      "        -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
      "        -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
      "        -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
      "        -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
      "        -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
      "        -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
      "        -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
      "        -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
      "        -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
      "        -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
      "        -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
      "        -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
      "        -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
      "        -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
      "        -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
      "        -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
      "        -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
      "        -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
      "        -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
      "        -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
      "        -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
      "        -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
      "        -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
      "        -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
      "        -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
      "        -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
      "        -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
      "        -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
      "        -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
      "        -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
      "        -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
      "        -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
      "        -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
      "        -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
      "        -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
      "        -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
      "        -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
      "        -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
      "        -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
      "        -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
      "        -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
      "        -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.],\n",
      "       device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "print(res[-1][0,:])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
